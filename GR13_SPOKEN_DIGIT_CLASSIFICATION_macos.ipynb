{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "raising-airline",
   "metadata": {},
   "source": [
    "# Assignment 1 - speech recognition - group 13\n",
    "### MacOS version\n",
    "\n",
    "steps:\n",
    "* data set preparation\n",
    "* getting the labels\n",
    "* MFCC computation\n",
    "* K-Fold CV to choose the algorithm\n",
    "* Train and test subsets splitting\n",
    "* Ranzomized Search for the hyperparameters\n",
    "* Random Forest algorithm\n",
    "* Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import metrics   \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-hygiene",
   "metadata": {},
   "source": [
    "## Data set preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svn\n",
    "!pip install svn\n",
    "import svn\n",
    "!svn checkout https://github.com/Jakobovski/free-spoken-digit-dataset/trunk/recordings repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 20   # number of MFCC we will use\n",
    "freq = 16000   # sampling rate\n",
    "\n",
    "#getting the list of files from the GitHub repository\n",
    "from pathlib import Path\n",
    "audiofiles = [str(file) for file in Path().glob('repo/*.wav')]\n",
    "\n",
    "# creating a dictionary to store data\n",
    "data = {'mfcc':[], 'labels':[]}\n",
    "\n",
    "for i,file in enumerate(audiofiles):\n",
    "    fileid = file.split('_')[0]\n",
    "    label  = fileid.split('/')[1]\n",
    "    data[\"labels\"].append(label)   #getting the labels\n",
    "    \n",
    "    #load the audio files\n",
    "    audio, sr = librosa.load(file, sr=freq)\n",
    "        \n",
    "    #compute the MFCCs for each audio file\n",
    "    mfcc = librosa.feature.mfcc(audio, sr=freq, n_fft =512, n_mfcc = n_mfcc)\n",
    "    feature_vector =np.mean(mfcc, axis = 1)\n",
    "    \n",
    "    #features_matrix[i,:] = feature_vector\n",
    "    data[\"mfcc\"].append(feature_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that I got all the 3000 audio files\n",
    "print('Got {} rows of data'.format(len(data['mfcc'])))\n",
    "\n",
    "# create the flattened matrix of MFCCs -->  go from a list of arrays to a 2D matrix\n",
    "MFCC_matrix =np.asarray( data['mfcc'])\n",
    "\n",
    "# ...same for the labels vector\n",
    "LABELS_vector = np.asarray(data[\"labels\"])\n",
    "\n",
    "print('Dimension of vector of labels is: {}'.format(LABELS_vector.shape))\n",
    "print('Dimension of matrix of feautures is: {}'.format(MFCC_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-example",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# listen to the last audio file loaded\n",
    "ipd.Audio(audio, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the MFCC heatmap for the last audio file\n",
    "librosa.display.specshow(mfcc,x_axis = 'time',sr=sr)\n",
    "plt.title('MFCC heatmap for {}'.format(file))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MFCCs')\n",
    "plt.colorbar()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-leonard",
   "metadata": {},
   "source": [
    "## K-Fold cross validation : Random Forest / SVC / kNN \n",
    "### (using cross_val_score) (k=10)\n",
    "\n",
    "The random state affects the splitting and that changes the accuracy score. We will evaluate the accuracy of these 3 algorithms using the K Fold cross validation. We will use the default values of the parameters during this process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()                                  # initialize SVM\n",
    "rf = RandomForestClassifier(n_jobs=2)        # initialize Random Forest\n",
    "knn = KNeighborsClassifier()                 # initialize KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector \n",
    "print('The accuracy for the SVM is {}'.\n",
    "      format(cross_val_score(svm, MFCC_matrix, LABELS_vector, cv=10, scoring='accuracy').mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "print('The accuracy for the Random Forest is {}'.\n",
    "      format(cross_val_score(rf, MFCC_matrix, LABELS_vector, cv=10, scoring='accuracy').mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN\n",
    "print('The accuracy for the KNN is {}'.\n",
    "      format(cross_val_score(knn, MFCC_matrix, LABELS_vector, cv=10, scoring='accuracy').mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-malpractice",
   "metadata": {},
   "source": [
    "The Random Forest algorithm shows the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-pricing",
   "metadata": {},
   "source": [
    "## Proportionate splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming\n",
    "y = LABELS_vector\n",
    "X = MFCC_matrix\n",
    "\n",
    "# splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=1, test_size=0.2, stratify=y)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how the test sample are the same number for each digit\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-third",
   "metadata": {},
   "source": [
    "## Random Forest - fine tuning\n",
    "### using RandomizedSearchCV\n",
    "Having chosen the Random Forest algorithm we can proceed and evaluate the best parameters to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,'max_features': max_features,'max_depth': max_depth,\n",
    "'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf,'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# We have already created the base model to tune\n",
    "# rf = RandomForestClassifier(n_jobs=2)\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=1, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the hyperparameters picked for the model\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-holmes",
   "metadata": {},
   "source": [
    "## PREDICTIONS AND RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict labels\n",
    "predicted = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "#confusion matrix\n",
    "print('CONFUSION MATRIX _ RANDOM FOREST:')\n",
    "disp=metrics.plot_confusion_matrix(rf_random, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-consciousness",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#classification report\n",
    "print('CLASSIFICATION REPORT _ RANDOM FOREST:\\n\\n',classification_report(y_test,predicted))\n",
    "print('Accuracy:\\n',accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check of the probabilities for a random sample\n",
    "print(\"The label for this sample in y_test is {}\".format((y_test)[60]))\n",
    "print(\"The random forest predicted for it {}\".format((predicted[60])))\n",
    "a = rf_random.predict_proba(X_test)\n",
    "print(\"Each class got these probabilities: {}\".format(a[60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-cambridge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
